# An√°lisis de Viabilidad - ADR-001: Soni Framework Architecture

**Proyecto:** Soni - Framework Open Source para Asistentes Conversacionales  
**Documento:** An√°lisis de Viabilidad T√©cnica  
**Fecha de An√°lisis:** 29 de Noviembre de 2025  
**Analista:** Jorge - AI Solutions Architect  
**Versi√≥n:** 1.0  
**Estado:** Aprobado

---

## Resumen Ejecutivo

Este documento presenta un an√°lisis exhaustivo de la viabilidad t√©cnica del ADR-001 de Soni Framework, basado en investigaci√≥n actualizada de las tecnolog√≠as propuestas (DSPy, LangGraph, MIPROv2, SIMBA, GEPA) y evaluaci√≥n del panorama competitivo actual.

**Veredicto General:** ‚úÖ **VIABLE con ajustes estrat√©gicos recomendados**

**Puntuaci√≥n de Viabilidad:** 8.5/10

---

## 1. An√°lisis de Tecnolog√≠as Core

### 1.1 DSPy y Optimizadores

#### Estado Actual: ‚úÖ EXCELENTE

**Versi√≥n Analizada:** DSPy 3.0.4 (Noviembre 2025)

**Novedades Importantes en DSPy 3.0:**
- **Async nativo**: Soporte completo para programas DSPy as√≠ncronos con `dspy.syncify` para ejecutar optimizadores en programas async
- **Streaming mejorado**: Streaming de tokens y estado desde cualquier capa, no solo salida final
- **Observabilidad**: Integraci√≥n nativa con MLflow 3.0 para tracing, tracking de optimizadores, y deployment
- **Adapters**: Sistema extensible (ChatAdapter, JSONAdapter, XMLAdapter, BAMLAdapter) con fallback inteligente
- **Tipos multi-modal**: dspy.Image, dspy.Audio, y tipos compuestos (list[dspy.Image], modelos Pydantic)
- **Escalabilidad**: Module.batch con DSPy settings thread-safe, caches de alta concurrencia configurables
- **Nuevos m√≥dulos**: dspy.CodeAct, dspy.Refine, ReAct mejorado, PythonInterpreter m√°s confiable
- **GRPO**: Biblioteca Arbor para entrenamiento RL de sistemas compound AI

#### MIPROv2 (Multiprompt Instruction Proposal Optimizer v2)

**Estado:** Activo y maduro

**Hallazgos:**
- DSPy 3.0 introduce mejoras significativas: escalabilidad con Module.batch y configuraciones thread-safe, soporte async nativo, caches de alta concurrencia, streaming de tokens y estado desde cualquier capa, tracking de uso, y callbacks enriquecidos
- Nuevos m√≥dulos: dspy.CodeAct, dspy.Refine, ReAct mejorado, y PythonInterpreter m√°s confiable
- Integraci√≥n nativa con MLflow 3.0 para trazabilidad, tracking de optimizadores, y flujos de deployment mejorados
- MIPROv2 sustancialmente m√°s confiable con selecci√≥n autom√°tica de hiperpar√°metros y m√∫ltiples correcciones
- Soporte para Adapters (ChatAdapter, JSONAdapter, XMLAdapter, BAMLAdapter) con streaming de tokens/estado, paths async, y fallback inteligente a salidas estructuradas nativas del LLM
- Tipos multi-modal v√≠a dspy.Image y dspy.Audio, tipos compuestos (list[dspy.Image], modelos Pydantic), y I/O de alto nivel como dspy.History y dspy.ToolCalls
- Implementaci√≥n estable con soporte completo para optimizaci√≥n conjunta de instrucciones y ejemplos few-shot
- Utiliza Optimizaci√≥n Bayesiana para b√∫squeda efectiva en el espacio de prompts
- Configuraci√≥n flexible: `auto="light|medium|heavy"` para diferentes presupuestos de optimizaci√≥n
- Soporte para optimizaci√≥n 0-shot (solo instrucciones) y few-shot (instrucciones + demos)

**C√≥digo de Ejemplo Verificado:**
```python
from dspy.teleprompt import MIPROv2

teleprompter = MIPROv2(
    metric=gsm8k_metric,
    auto="medium",  # light, medium, heavy
)

optimized_program = teleprompter.compile(
    dspy.ChainOfThought("question -> answer"),
    trainset=gsm8k.train,
)
```

**Fuentes:**
- Documentaci√≥n oficial DSPy: https://dspy.ai/api/optimizers/MIPROv2/
- Paper: "MIPROv2: Optimizing Prompts via Multi-stage Instruction Proposal"
- Integraci√≥n con LangWatch para UI de baja-c√≥digo disponible

#### SIMBA (Stochastic Introspective Mini-Batch Ascent)

**Estado:** Activo y en producci√≥n

**Hallazgos:**
- Usa muestreo mini-batch estoc√°stico para identificar ejemplos desafiantes con alta variabilidad de salida
- El LLM analiza introspectivamente sus propios fallos
- Genera reglas de mejora auto-reflexivas o a√±ade demos exitosas
- Mayor eficiencia de muestra y estabilidad vs MIPROv2 en LLMs avanzados

**Caracter√≠sticas Clave:**
- Auto-introspecci√≥n del modelo
- Mejor rendimiento con modelos m√°s capaces (GPT-4, Claude, etc.)
- Ideal para tareas agentic/long-horizon

**C√≥digo de Ejemplo:**
```python
from dspy.teleprompt import SIMBA

optimizer = dspy.SIMBA(
    metric=your_metric,
    max_steps=12,
    max_demos=10
)
optimized_program = optimizer.compile(
    your_dspy_program, 
    trainset=trainset
)
```

#### GEPA (Genetic-Pareto Optimizer)

**Estado:** ‚úÖ ESTADO DEL ARTE (Introducido 2025)

**Hallazgos Cr√≠ticos:**
- Paper: "GEPA: Reflective Prompt Evolution Can Outperform Reinforcement Learning" (Agrawal et al., 2025)
- Mejoras de hasta 11% sobre MIPROv2 en diversos benchmarks
- Extremadamente eficiente con pocos datos (34 ejemplos en casos documentados)
- +10% de mejora en AIME 2025 con GPT-4o Mini

**Caracter√≠sticas Revolucionarias:**
- Evoluci√≥n reflexiva de prompts usando feedback textual
- Construcci√≥n de √°rbol Pareto de prompts
- Puede producir prompts m√°s cortos mientras mejora rendimiento
- Soporte para multi-objetivo (accuracy, safety, compliance)

**C√≥digo de Ejemplo:**
```python
import dspy

teleprompter = dspy.GEPA(
    metric=your_feedback_metric,  # Puede retornar texto + score
    auto="light",
    use_merge=True,
    num_threads=4
)

optimized = teleprompter.compile(
    student=your_program,
    trainset=trainset,
    valset=valset
)
```

**Ventaja √önica:** Acepta feedback textual rico, no solo scores escalares.

#### Integraci√≥n MLflow

**Estado:** ‚úÖ Disponible

GEPA est√° integrado en MLflow 3.0+ a trav√©s de `mlflow.genai.optimize_prompts()` API para optimizaci√≥n autom√°tica de prompts usando m√©tricas de evaluaci√≥n.

#### Conclusi√≥n Tecnol√≥gica - DSPy

**Veredicto:** ‚úÖ‚úÖ‚úÖ **EXTREMADAMENTE VIABLE**

**Fortalezas:**
- Ecosystem maduro y activamente mantenido por Stanford NLP (con soporte adicional de Databricks)
- **DSPy 3.0** introduce mejoras cr√≠ticas: async nativo, streaming completo, escalabilidad thread-safe
- Tres optimizadores state-of-the-art disponibles (MIPROv2 mejorado, SIMBA, GEPA)
- Integraci√≥n nativa con MLflow 3.0 para observabilidad, tracing y tracking de optimizadores
- Sistema de **Adapters** para diferentes formatos (Chat, JSON, XML, BAML) con fallback inteligente
- Tipos multi-modal (dspy.Image, dspy.Audio) y tipos compuestos (Pydantic models)
- Biblioteca **Arbor** para GRPO (RL training de sistemas compound AI)
- Soporte completo para m√≥dulos async (`acall()`) y batch processing
- Composici√≥n de optimizadores permitida (pipeline optimization)

**Riesgos:**
- Desarrollo r√°pido puede introducir cambios menores entre versiones 3.0.x
- DSPy 3.0 es estable pero el ecosistema sigue evolucionando
- Breaking change menor en 3.0: retriever integration descontinuado (afecta a muy pocos usuarios)

**Recomendaci√≥n:** 
- ‚úÖ Usar como pilar central de la arquitectura
- Pin versi√≥n: `dspy>=3.0.4,<4.0.0`
- Tu propuesta de `SoniDU(dspy.Module)` es el approach correcto
- Aprovechar nuevas caracter√≠sticas de 3.0: async nativo, streaming, Adapters

---

### 1.2 LangGraph - Orquestaci√≥n y Streaming

#### Estado Actual: ‚úÖ EXCELENTE

**Versi√≥n Analizada:** LangGraph 1.0.4 (Noviembre 2025)

#### Soporte As√≠ncrono

**Estado:** ‚úÖ Production-ready

**Hallazgos:**
- Soporte nativo completo para async/await
- M√©todos async: `.ainvoke()`, `.astream()`, `.astream_events()`
- Compatible con Python 3.11+ (contextvars propagation autom√°tica)
- Zero overhead para workflows as√≠ncronos

**Nota sobre Python < 3.11:**
- En Python 3.8-3.10 se requiere pasar `RunnableConfig` expl√≠citamente
- No se puede usar `get_stream_writer` en nodos async (usar argumento `writer`)
- **Recomendaci√≥n:** Target Python 3.11+ para mejor DX

#### Streaming System

**Estado:** ‚úÖ Producci√≥n con m√∫ltiples modos

**Modos de Streaming Disponibles:**

1. **`values`** - Estado completo despu√©s de cada paso
2. **`updates`** - Deltas incrementales del estado
3. **`messages`** - Tokens LLM + metadata
4. **`custom`** - Datos arbitrarios definidos por usuario
5. **`debug`** - Trazas detalladas para debugging

**C√≥digo de Ejemplo Verificado:**
```python
# Streaming async b√°sico
async for chunk in graph.astream(input, stream_mode="values"):
    print(chunk)

# Streaming de tokens LLM
async for event in graph.astream_events(input, version="v2"):
    if event["event"] == "on_chat_model_stream":
        token = event["data"]["chunk"].content
        print(token, end="")
```

**Streaming Custom en Nodos:**
```python
from langgraph.types import StreamWriter

async def streaming_node(state, writer: StreamWriter):
    for word in message.split():
        writer(AIMessageChunk(content=word))
    return {"messages": final_message}
```

#### Compatibilidad con FastAPI

**Estado:** ‚úÖ Integraci√≥n nativa

**Hallazgos:**
- Dise√±o espec√≠fico para streaming workflows
- Sin overhead adicional
- Patrones documentados para FastAPI + LangGraph + Streamlit

**Ejemplo de Integraci√≥n:**
```python
from fastapi import FastAPI
from fastapi.responses import StreamingResponse

app = FastAPI()

@app.post("/chat/stream")
async def chat_stream(message: str):
    async def generate():
        async for chunk in graph.astream({"messages": [message]}):
            yield chunk
    
    return StreamingResponse(generate(), media_type="text/event-stream")
```

#### Persistencia y Checkpointing

**Estado:** ‚úÖ Soporte completo

**Backends Soportados:**
- SQLite (sync y async con aiosqlite)
- PostgreSQL (async con asyncpg)
- Redis (async con aioredis)
- Custom checkpointers

**Tu Propuesta:**
```yaml
persistence:
  backend: sqlite
  path: ./data/dialogue.db
```

**Validaci√≥n:** ‚úÖ Completamente soportado

#### LangGraph Studio

**Estado:** ‚úÖ Disponible

- Herramienta visual para debugging y prototipado
- Deploy 1-click con LangGraph Platform
- Monitoreo con LangSmith integration

#### Desarrollo y Mantenimiento

**Estado:** ‚úÖ Muy activo

- Releases frecuentes (√∫ltima: 1.0.4 en Nov 2025)
- Desarrollo por LangChain (empresa con funding)
- Documentaci√≥n completa y en mejora constante
- Usado en producci√≥n por empresas (Klarna, Replit, Elastic)

#### Conclusi√≥n Tecnol√≥gica - LangGraph

**Veredicto:** ‚úÖ‚úÖ‚úÖ **EXTREMADAMENTE VIABLE**

**Fortalezas:**
- Arquitectura async-first sin overhead
- Sistema de streaming robusto y flexible
- M√∫ltiples backends de persistencia
- Integraci√≥n natural con FastAPI
- Ecosistema maduro y bien mantenido

**Riesgos:**
- En fase 1.0.x, posibles cambios menores en API
- Dependencia de LangChain ecosystem

**Recomendaci√≥n:**
- ‚úÖ Usar como runtime principal
- Pin versi√≥n: `langgraph>=1.0.0,<1.1.0`
- Tu arquitectura async es completamente viable
- Streaming nativo cumple todos tus requisitos

---

### 1.3 Bibliotecas Auxiliares

#### aiosqlite / asyncpg / aioredis

**Estado:** ‚úÖ Maduras y estables

- `aiosqlite`: Wrapper async sobre sqlite3
- `asyncpg`: Driver PostgreSQL async de alto rendimiento
- `aioredis`: Cliente Redis async (ahora parte de redis-py)

**Recomendaci√≥n:** Soportadas, usar sin problemas.

#### FastAPI

**Estado:** ‚úÖ Industry standard

- Framework async de facto para Python
- Validaci√≥n con Pydantic
- OpenAPI/Swagger autom√°tico
- Streaming nativo con Server-Sent Events

**Recomendaci√≥n:** Elecci√≥n perfecta para tu API layer.

---

## 2. An√°lisis del Panorama Competitivo

### 2.1 Rasa - Evaluaci√≥n Actualizada

#### Tu Evaluaci√≥n Original (ADR)

> "Rasa: Activo, pero bifurcado. Innovaci√≥n LLM restringida a versi√≥n comercial (Pro). Versi√≥n OS mantiene arquitectura legacy."

#### Hallazgos de Investigaci√≥n (Nov 2025)

**Estado Real:** ‚ö†Ô∏è **TU EVALUACI√ìN ES PARCIALMENTE CORRECTA PERO NECESITA MATICES**

#### Rasa Open Source

**Estado:** Activo pero con limitaciones LLM

- Componentes LLM disponibles en **beta** (experimental)
- `LLMIntentClassifier` usando RAG disponible en OS
- Configuraci√≥n b√°sica de LLMs (OpenAI, Azure) soportada
- **PERO:** Caracter√≠sticas avanzadas exclusivas de Rasa Pro

**Caracter√≠sticas OS:**
- Intent classification con LLM (RAG-based)
- Few-shot learning
- Multilingual support
- Configuraci√≥n de temperatura, prompts, etc.

**Limitaciones OS:**
- Sin CALM architecture
- Sin CompactLLMCommandGenerator
- Sin LLMBasedRouter avanzado
- Sin ContextualResponseRephraser
- Sin Rasa Studio (UI visual)

#### Rasa Pro (Versi√≥n Comercial)

**Estado:** ‚úÖ **MUY COMPETITIVO** (Actualizaci√≥n cr√≠tica para tu ADR)

**Arquitectura CALM (Conversational AI with Language Models):**
- Introducida en 2024-2025
- Paradigm shift completo hacia LLM-native
- Integraci√≥n de LLMs manteniendo determinismo empresarial

**Componentes Avanzados (Rasa Pro):**

1. **CompactLLMCommandGenerator** (Nuevo en 3.12+)
   - Prompts optimizados para GPT-4o y Claude 3.5 Sonnet
   - 10x reducci√≥n de costes vs generadores anteriores
   - Multi-step command generation

2. **LLMBasedRouter**
   - Routing inteligente entre flujos CALM
   - Soporte sticky/non-sticky routing
   - Multi-LLM routing para escalado

3. **ContextualResponseRephraser**
   - Rephrasing contextual de respuestas
   - Mantiene control sobre contenido base

4. **Rasa Studio** (UI No-Code)
   - Visual Flow Builder drag-and-drop
   - Prompt Engineering integrado
   - Voice testing 1-click
   - Colaboraci√≥n para no-t√©cnicos

**Modelos Soportados (Rasa Pro 3.13+):**
- GPT-4o (2024-11-20)
- GPT-4.1-mini (2025-04-14)
- Claude 3.5 Sonnet (2024-06-20)
- Embeddings: text-embedding-3-large

**Caracter√≠sticas Empresariales:**
- Multi-language support con traducciones autom√°ticas
- ReAct-style agents nativos
- Call steps para invocar agents desde flows
- LLM Judge para testing E2E
- Enterprise Search Policy

#### Implicaciones para Soni

**Conclusi√≥n:** Rasa Pro es **significativamente m√°s competitivo** de lo que tu ADR sugiere.

**¬øInvalida tu propuesta?** ‚ùå **NO, pero cambia tu posicionamiento**

**Diferenciadores de Soni vs Rasa Pro:**

| Aspecto | Soni | Rasa Pro |
|---------|------|----------|
| **Licencia** | ‚úÖ 100% Open Source | ‚ùå Comercial (precio no p√∫blico) |
| **Optimizaci√≥n** | ‚úÖ Autom√°tica (DSPy) | ‚ùå Manual (prompt engineering) |
| **Bifurcaci√≥n** | ‚úÖ Sin split OS/Pro | ‚ùå Features clave en Pro |
| **Control** | ‚úÖ Total (self-hosted) | ‚ö†Ô∏è Depende del plan |
| **LLM Support** | ‚úÖ DSPy-native | ‚úÖ LLM-native (CALM) |
| **UI Visual** | ‚ö†Ô∏è Pendiente | ‚úÖ Rasa Studio |
| **Enterprise** | ‚ö†Ô∏è Por construir | ‚úÖ Maduro |

**Tu Ventaja Real:**

1. **Optimizaci√≥n Autom√°tica** - El killer feature
   - Rasa Pro usa prompt engineering manual
   - T√∫ usas MIPROv2/SIMBA/GEPA autom√°tico
   - Esto es un **game-changer** para equipos sin expertos en prompting

2. **100% Open Source** - Sin vendor lock-in
   - Rasa bifurca innovaci√≥n hacia Pro
   - T√∫ mantienes todo en OS

3. **DSPy-First Architecture**
   - Programas, no prompteas
   - M√≥dulos optimizables de forma sistem√°tica
   - Composabilidad nativa

**Recomendaci√≥n Cr√≠tica:**

‚ö†Ô∏è **REPOSICIONA TU PROPUESTA DE VALOR**

**En lugar de:**
> "Rasa est√° obsoleto en LLMs"

**Di:**
> "Soni elimina el prompt engineering manual mediante optimizaci√≥n autom√°tica con DSPy, mientras que otros frameworks (incluyendo Rasa Pro comercial) requieren tuning manual de prompts. 100% open source, sin bifurcaci√≥n comercial."

---

### 2.2 Otros Competidores

#### Botpress

**Estado:** Cloud-first con OS secundario

- Enfoque en SaaS
- Versi√≥n self-hosted existe pero es secundaria
- UI visual fuerte
- **Tu ventaja:** Open source puro, optimizaci√≥n autom√°tica

#### Chatterbot

**Estado:** Legacy en mantenimiento

- Arquitectura obsoleta
- Soporte LLM experimental y fr√°gil
- **Tu ventaja:** Todo tu stack moderno

#### Parlant

**Estado:** Inmaduro con problemas

- Problemas de latencia reportados (9x overhead)
- Framework muy joven
- **Tu ventaja:** LangGraph probado + DSPy maduro

---

## 3. Evaluaci√≥n de la Arquitectura Propuesta

### 3.1 Arquitectura H√≠brida Desacoplada

**Evaluaci√≥n:** ‚úÖ **EXCELENTE DISE√ëO**

**Componentes Core:**

#### SoniDU (Dialogue Understanding)

```python
class SoniDU(dspy.Module):
    async def acall(self, input: str) -> Command:
        # Traducir entrada a comando estructurado
        pass
```

**Validaci√≥n:** ‚úÖ Pattern correcto
- Hereda de `dspy.Module` ‚úì
- Usa `acall()` para async ‚úì
- Retorna estructura validable ‚úì

#### Dynamic Scoping

**Concepto:** Inyectar solo acciones relevantes en contexto LLM

**Evaluaci√≥n:** ‚úÖ CR√çTICO PARA ESCALABILIDAD

**Problema que resuelve:**
- Sin scoping: 100 acciones ‚Üí contexto saturado ‚Üí precisi√≥n baja
- Con scoping: 5-10 acciones relevantes ‚Üí contexto limpio ‚Üí precisi√≥n alta

**Implementaci√≥n sugerida:**
```python
class DynamicScoper:
    async def get_relevant_actions(
        self, 
        current_state: DialogueState,
        intent: str
    ) -> List[Action]:
        # Filtrado sem√°ntico con embeddings
        # O reglas basadas en flow actual
        pass
```

**Riesgo:** Complejidad media
**Recomendaci√≥n:** Empieza con scoping basado en flows, a√±ade sem√°ntico despu√©s.

#### Normalization Layer

**Concepto:** Puente entre salida "blanda" del LLM y validaci√≥n "dura"

**Ejemplo:**
```
User: "Quiero volar a Madriz ma√±ana"
LLM extrae: "Madriz, probablemente Madrid"
Normalizer: "Madriz" ‚Üí "Madrid" (fuzzy match + LLM)
Validator: "Madrid" ‚úì (en lista de ciudades)
```

**Evaluaci√≥n:** ‚úÖ ESENCIAL PARA ROBUSTEZ

**Estrategias:**
1. Heur√≠sticas (trim, lowercase, fuzzy matching)
2. LLM correction (para casos ambiguos)
3. Fallback a usuario (cuando confianza baja)

**Tu Propuesta en YAML:**
```yaml
entities:
  - name: city
    normalization:
      strategy: llm_correction  # ‚úì Correcto
  - name: date
    normalization:
      strategy: trim  # ‚úì Correcto
```

**Recomendaci√≥n:** Implementar en fases
- v0.1.0 (MVP): Solo heur√≠sticas
- v0.2.0: A√±adir LLM correction

#### Step Compiler (v0.3.0)

**Concepto:** Traducir YAML procedural a LangGraph StateGraph

**Entrada (YAML):**
```yaml
process:
  - step: collect_origin
  - step: collect_destination
  - step: search_flights
    conditions:
      - if: "no_results"
        jump_to: suggest_alternatives
```

**Salida (Python):**
```python
graph = StateGraph(DialogueState)
graph.add_node("collect_origin", collect_origin_fn)
graph.add_node("collect_destination", collect_destination_fn)
graph.add_node("search_flights", search_flights_fn)
graph.add_conditional_edges("search_flights", route_fn)
```

**Evaluaci√≥n:** ‚ö†Ô∏è **COMPLEJIDAD ALTA PERO VIABLE**

**Desaf√≠os:**
1. Parsear condiciones complejas
2. Generar funciones de routing din√°micas
3. Mantener trazabilidad YAML ‚Üî Graph
4. Validar que el grafo resultante es v√°lido

**Recomendaci√≥n:**
- v0.1.0 (MVP): Solo steps lineales (secuencia simple)
- v0.3.0: A√±adir condicionales y jumps
- Usar AST manipulation para generar c√≥digo limpio
- Tests exhaustivos de compilaci√≥n

**Riesgo:** Si falla, todo el framework falla
**Mitigaci√≥n:** Suite de tests golden-path + edge cases

---

### 3.2 Zero-Leakage Architecture (v0.4.0)

**Evaluaci√≥n:** ‚úÖ‚úÖ‚úÖ **DISE√ëO BRILLANTE - DIFERENCIADOR CLAVE**

Esta es tu **innovaci√≥n arquitect√≥nica** m√°s importante.

#### Problema que Resuelve

**Antes (v0.3.0):**
```yaml
actions:
  search_flights:
    type: http
    method: POST  # ‚ùå Detalle t√©cnico
    url: "https://api.example.com/flights"  # ‚ùå Acoplamiento
    body:
      origin: "{origin}"
    jsonpath: "$.data.flights"  # ‚ùå Estructura interna
```

**Despu√©s (v0.4.0):**
```yaml
actions:
  search_flights:
    description: "Busca vuelos disponibles"  # ‚úì Sem√°ntico
    params:
      - origin
      - destination
      - date
    map_outputs:
      flight_count: num_results  # ‚úì Mapeo desacoplado
```

#### Action Registry

**Implementaci√≥n Python:**
```python
from soni.registry import action

@action("search_flights")
async def search_flights_impl(
    origin: str,
    destination: str,
    date: datetime
) -> FlightSearchResult:
    # Toda la l√≥gica HTTP aqu√≠
    async with httpx.AsyncClient() as client:
        response = await client.post(
            "https://api.example.com/flights",
            json={...}
        )
    return FlightSearchResult.parse(response.json())
```

**Ventajas:**
1. ‚úÖ Analistas editan YAML sin romper integraciones
2. ‚úÖ Devs cambian APIs sin tocar YAML
3. ‚úÖ Testing independiente (mock actions)
4. ‚úÖ Versionado separado (business logic vs tech)

#### Validator Registry

**Implementaci√≥n:**
```python
from soni.registry import validator

@validator("is_valid_iata_code")
def validate_iata(value: str) -> bool:
    # Regex oculta, nombre sem√°ntico expuesto
    return re.match(r'^[A-Z]{3}$', value) is not None

@validator("is_future_date")
def validate_future_date(value: datetime) -> bool:
    return value > datetime.now()
```

**YAML:**
```yaml
entities:
  - name: airport_code
    validators:
      - is_valid_iata_code  # ‚úì Legible por humanos
  - name: departure_date
    validators:
      - is_future_date  # ‚úì Sem√°ntico
```

#### Output Mapping

**Problema:**
```python
# API retorna:
{
  "data": {
    "search_results": {
      "total": 42,
      "items": [...]
    }
  }
}
```

**Sin mapping (v0.3.0):**
```yaml
# Usuario necesita saber estructura interna ‚ùå
response_template: "Encontr√© {res.data.search_results.total} vuelos"
```

**Con mapping (v0.4.0):**
```yaml
# Action define mapeo
map_outputs:
  flight_count: data.search_results.total
  flights: data.search_results.items

# Usuario usa nombres sem√°nticos ‚úì
response_template: "Encontr√© {flight_count} vuelos"
```

**Implementaci√≥n:**
```python
@action("search_flights")
async def search_flights_impl(...) -> dict:
    result = await call_api(...)
    return {
        "flight_count": result["data"]["search_results"]["total"],
        "flights": result["data"]["search_results"]["items"]
    }
```

#### Conclusi√≥n Zero-Leakage

**Veredicto:** ‚úÖ‚úÖ‚úÖ **ESTE ES TU MOAT**

**Valor √önico:**
- Ning√∫n framework ToD open source tiene esta separaci√≥n
- Rasa Pro lo intenta con CALM Flows pero no al nivel de abstracci√≥n que propones
- Es tu ventaja competitiva #1 junto con optimizaci√≥n DSPy

**Complejidad:**
- Media-Alta para implementar
- Requiere reflection/introspection cuidadosa
- Testing riguroso de registry system

**Recomendaci√≥n:**
- ‚úÖ Mantener como objetivo core
- Implementar en v0.4.0 (despu√©s de consolidar base)
- Documentaci√≥n exhaustiva para developers
- Examples claros de c√≥mo extender

---

## 4. Riesgos y Mitigaciones

### 4.1 Riesgos T√©cnicos

#### Riesgo 1: Complejidad del Step Compiler

**Probabilidad:** Media  
**Impacto:** Alto  
**Severidad:** ‚ö†Ô∏è MEDIO-ALTO

**Descripci√≥n:**
Traducir YAML procedural a StateGraph puede introducir bugs dif√≠ciles de depurar.

**Mitigaci√≥n:**
1. Suite de tests exhaustiva
2. Validaci√≥n de YAML en tiempo de carga
3. Generaci√≥n de visualizaci√≥n del grafo resultante
4. Logging detallado de compilaci√≥n
5. Empezar con subset simple de features

**Implementaci√≥n sugerida:**
```python
class StepCompiler:
    def validate_yaml(self, yaml_config: dict) -> List[ValidationError]:
        """Validar antes de compilar"""
        pass
    
    def compile(self, yaml_config: dict) -> StateGraph:
        """Compilar con validaci√≥n"""
        errors = self.validate_yaml(yaml_config)
        if errors:
            raise CompilationError(errors)
        
        graph = self._build_graph(yaml_config)
        self._validate_graph(graph)
        return graph
    
    def visualize(self, graph: StateGraph) -> str:
        """Generar mermaid diagram para debugging"""
        pass
```

#### Riesgo 2: Rendimiento del Normalizer

**Probabilidad:** Media  
**Impacto:** Medio  
**Severidad:** ‚ö†Ô∏è MEDIO

**Descripci√≥n:**
Llamadas LLM adicionales para normalizaci√≥n pueden aumentar latencia.

**Mitigaci√≥n:**
1. Cache de normalizaciones frecuentes
2. Heur√≠sticas primero, LLM solo si necesario
3. Normalizaci√≥n async no-bloqueante
4. Threshold de confianza para skip LLM

**Implementaci√≥n:**
```python
class Normalizer:
    def __init__(self):
        self.cache = TTLCache(maxsize=1000, ttl=3600)
    
    async def normalize(
        self, 
        value: str, 
        entity_type: str
    ) -> NormalizedValue:
        # 1. Check cache
        cache_key = f"{entity_type}:{value}"
        if cache_key in self.cache:
            return self.cache[cache_key]
        
        # 2. Try heuristics
        heuristic_result = self.apply_heuristics(value, entity_type)
        if heuristic_result.confidence > 0.9:
            self.cache[cache_key] = heuristic_result
            return heuristic_result
        
        # 3. Fallback to LLM
        llm_result = await self.llm_normalize(value, entity_type)
        self.cache[cache_key] = llm_result
        return llm_result
```

#### Riesgo 3: Breaking Changes en Dependencias

**Probabilidad:** Media  
**Impacto:** Alto  
**Severidad:** ‚ö†Ô∏è MEDIO-ALTO

**Descripci√≥n:**
DSPy y LangGraph est√°n en desarrollo activo. Breaking changes pueden romper Soni.

**Mitigaci√≥n:**
1. **Version pinning estricto:**
   ```
   dspy>=3.0.4,<4.0.0
   langgraph>=1.0.0,<1.1.0
   langchain-core>=0.3.0,<0.4.0
   ```

2. **Tests de integraci√≥n continuos:**
   ```python
   # tests/integration/test_dependencies.py
   def test_dspy_module_interface():
       """Verificar que dspy.Module API no ha cambiado"""
       assert hasattr(dspy.Module, 'forward')
       assert hasattr(dspy.Module, '__call__')
   
   def test_langgraph_streaming():
       """Verificar que streaming API funciona"""
       # ...
   ```

3. **Monitoring de repos:**
   - GitHub watch de stanfordnlp/dspy
   - GitHub watch de langchain-ai/langgraph
   - Alertas de nuevos releases

4. **Estrategia de actualizaci√≥n:**
   - Probar nuevas versiones en branch separada
   - Actualizar solo minor/patch, no major sin evaluaci√≥n
   - Mantener changelog de compatibilidad

#### Riesgo 4: Over-Engineering

**Probabilidad:** Alta  
**Impacto:** Alto  
**Severidad:** ‚ö†Ô∏è‚ö†Ô∏è ALTO

**Descripci√≥n:**
Tu arquitectura completa (ADR v1.3 ‚Üí Soni v0.4.0) es ambiciosa. Riesgo de gastar 12 meses sin MVP funcional.

**Mitigaci√≥n:**
‚úÖ **IMPLEMENTACI√ìN INCREMENTAL OBLIGATORIA**

Ver secci√≥n 5 (Roadmap Revisado) para plan detallado.

**Principios:**
1. **MVP First** - Funcionalidad antes que elegancia
2. **Validaci√≥n Temprana** - Users reales cuanto antes
3. **Refactoring Iterativo** - No dise√±es todo upfront
4. **Kill Your Darlings** - Si algo no aporta valor, elim√≠nalo

---

### 4.2 Riesgos de Mercado

#### Riesgo 1: Rasa Pro Evoluciona M√°s R√°pido

**Probabilidad:** Media  
**Impacto:** Medio  
**Severidad:** ‚ö†Ô∏è MEDIO

**Descripci√≥n:**
Rasa tiene equipo grande y funding. Pueden innovar m√°s r√°pido.

**Mitigaci√≥n:**
1. **Enfocarte en tu diferenciador:** Optimizaci√≥n autom√°tica
2. **Comunidad open source:** Contribuidores externos
3. **Nicho espec√≠fico:** Devs que quieren control total + auto-optimization
4. **Velocidad de iteraci√≥n:** Como solo eres t√∫, puedes pivotar r√°pido

#### Riesgo 2: Aparece Nuevo Competidor

**Probabilidad:** Media  
**Impacto:** Medio  
**Severidad:** ‚ö†Ô∏è MEDIO

**Descripci√≥n:**
Alguien m√°s podr√≠a tener idea similar (DSPy + LangGraph framework).

**Mitigaci√≥n:**
1. **Time to market:** Lanzar MVP r√°pido
2. **Documentaci√≥n excellent:** Ser el m√°s f√°cil de usar
3. **Casos de uso claros:** Ejemplos end-to-end que funcionen
4. **Comunidad:** Engagement activo, responsive a issues

---

## 5. Roadmap Revisado - Implementaci√≥n Incremental

### Filosof√≠a

‚ö†Ô∏è **NO IMPLEMENTES TODO A LA VEZ**

El ADR-001 (v1.3) define el estado final deseado, que se alcanzar√° en **Soni v1.0.0**. El camino para llegar debe ser **iterativo y validado**, pasando por versiones 0.1.0 ‚Üí 0.4.0 antes del release estable.

### Estrategia de Versionado

**Principio:** La versi√≥n 1.0.0 solo se alcanzar√° cuando el ADR-001 est√© **completamente implementado y validado**.

**Mapeo ADR ‚Üí Versiones Soni:**
- **ADR v1.0 (Base):** Implementado en Soni v0.1.0 (MVP)
- **ADR v1.1 (Scoping + Normalization):** Implementado en Soni v0.2.0
- **ADR v1.2 (Step Compiler):** Implementado en Soni v0.3.0
- **ADR v1.3 (Zero-Leakage):** Implementado en Soni v0.4.0
- **ADR Completo + Validaci√≥n:** Soni v1.0.0 (Stable Release)

**Versiones Pre-1.0:**
- `0.1.0` - Alpha: MVP funcional b√°sico
- `0.2.0` - Beta: Performance y UX mejoradas
- `0.3.0` - Beta Avanzado: DSL Compiler completo
- `0.4.0` - Release Candidate: Arquitectura Zero-Leakage completa
- `1.0.0` - Stable: ADR completo, validado y listo para producci√≥n

### Resumen del Roadmap

| Fase | Versi√≥n | ADR Equivalente | Duraci√≥n | Estado Objetivo |
|------|---------|-----------------|----------|-----------------|
| 1 | v0.1.0 | ADR v1.0 (Base) | 3 meses | MVP funcional |
| 2 | v0.2.0 | ADR v1.1 | 2 meses | Performance y UX |
| 3 | v0.3.0 | ADR v1.2 | 2 meses | DSL Compiler |
| 4 | v0.4.0 | ADR v1.3 | 3 meses | Zero-Leakage completo |
| 5 | v1.0.0 | ADR completo | 1-2 meses | Release estable |
| **Total** | | | **11-13 meses** | **ADR completamente implementado** |

### Fase 1: MVP Funcional ‚Üí v0.1.0 (3 meses)

**Objetivo:** Sistema ToD b√°sico funcional con optimizaci√≥n DSPy

**Versi√≥n Objetivo:** `0.1.0` (Alpha)

**Features Core:**
- ‚úÖ SoniDU como `dspy.Module` con intent + entity extraction
- ‚úÖ Optimizaci√≥n con MIPROv2 (solo light mode)
- ‚úÖ LangGraph StateGraph manual (sin compiler)
- ‚úÖ Steps lineales en YAML (sin condicionales)
- ‚úÖ Persistencia SQLite b√°sica (sync est√° ok para MVP)
- ‚úÖ Actions hardcoded en Python (sin registry todav√≠a)
- ‚úÖ Validaci√≥n b√°sica con Pydantic

**YAML Simplificado (MVP):**
```yaml
version: "0.1"

settings:
  models:
    nlu:
      provider: openai
      model: gpt-4o-mini

flows:
  book_flight:
    description: "Book a flight"
    steps:
      - collect: origin
      - collect: destination
      - collect: date
      - action: search_flights
    
slots:
  origin:
    type: string
    prompt: "Which city are you flying from?"
  destination:
    type: string
    prompt: "Where do you want to go?"
  date:
    type: date
    prompt: "When do you want to travel?"

actions:
  search_flights:
    handler: "handlers.flights.search"  # Python path
```

**Criterios de √âxito:**
- [ ] Usuario puede tener conversaci√≥n completa de booking
- [ ] Sistema es optimizable con MIPROv2
- [ ] Mejora medible en accuracy post-optimizaci√≥n
- [ ] Respuestas en <2 segundos

**Tiempo Estimado:** 2-3 meses (1 persona full-time)

**Deliverables:**
- C√≥digo en GitHub
- README con quickstart
- 1 ejemplo funcional end-to-end
- Tests b√°sicos

---

### Fase 2: Performance y UX ‚Üí v0.2.0 (2 meses)

**Objetivo:** Sistema production-ready con optimizaciones clave

**Versi√≥n Objetivo:** `0.2.0` (Beta)

**Features:**
- ‚úÖ **Async Everything** - Migrar todo a async/await
- ‚úÖ **Dynamic Scoping** - Filtrado de acciones por contexto
- ‚úÖ **Normalization Layer** - Heur√≠sticas + LLM correction
- ‚úÖ **Streaming** - Tokens en tiempo real
- ‚úÖ **FastAPI Integration** - REST API completa
- ‚úÖ **Persistencia Async** - aiosqlite/asyncpg
- ‚úÖ **SIMBA Optimizer** - A√±adir como alternativa a MIPROv2

**Arquitectura:**
```python
# soni/core.py
class SoniDU(dspy.Module):
    async def acall(self, input: str, context: Context) -> Command:
        # Dynamic scoping
        relevant_actions = await self.scoper.get_relevant(context)
        
        # LLM call con contexto filtrado
        command = await self.predict(input, relevant_actions)
        
        # Normalization
        normalized = await self.normalizer.normalize(command)
        
        return normalized
```

**Criterios de √âxito:**
- [ ] Latencia p95 < 1.5s
- [ ] Streaming funcional en frontend
- [ ] API RESTful completa
- [ ] Soporte para 10+ conversaciones concurrentes

**Tiempo Estimado:** 1.5-2 meses

**Deliverables:**
- FastAPI endpoints documentados
- Ejemplo con frontend (React/Vue simple)
- Performance benchmarks
- Gu√≠a de deployment

---

### Fase 3: DSL Compiler ‚Üí v0.3.0 (2 meses)

**Objetivo:** YAML procedural con Step Compiler

**Versi√≥n Objetivo:** `0.3.0` (Beta Avanzado)

**Features:**
- ‚úÖ **Step Compiler** - YAML ‚Üí StateGraph autom√°tico
- ‚úÖ **Conditional Flows** - If/else, jumps
- ‚úÖ **Loop Support** - Retry logic, confirmations
- ‚úÖ **Graph Visualization** - Mermaid diagrams auto-generados
- ‚úÖ **YAML Validation** - Schema completo con errores claros

**YAML Avanzado:**
```yaml
flows:
  book_flight:
    process:
      - step: collect_info
      - step: search_flights
        on_error:
          action: log_error
          next: ask_retry
      - step: confirm_booking
        conditions:
          - if: "price > 1000"
            action: escalate_to_human
          - else:
            next: process_payment
      - step: process_payment
        on_success: send_confirmation
        on_failure: 
          jump_to: payment_retry
```

**Implementaci√≥n:**
```python
# soni/compiler.py
class StepCompiler:
    def compile(self, yaml_config: dict) -> CompiledGraph:
        # Parse y validar
        validated = self.validator.validate(yaml_config)
        
        # Build graph
        graph = StateGraph(DialogueState)
        
        for flow_name, flow_def in validated.flows.items():
            self._compile_flow(graph, flow_name, flow_def)
        
        return CompiledGraph(
            graph=graph,
            metadata=self._extract_metadata(yaml_config)
        )
    
    def _compile_flow(self, graph, flow_name, flow_def):
        steps = flow_def['process']
        
        for i, step in enumerate(steps):
            node_fn = self._create_node_fn(step)
            graph.add_node(f"{flow_name}_{i}", node_fn)
            
            if i > 0:
                self._add_edge(graph, steps[i-1], step)
        
        # Handle conditions
        for step in steps:
            if 'conditions' in step:
                self._add_conditional_edges(graph, step)
```

**Criterios de √âxito:**
- [ ] Compiler genera grafos v√°lidos para 95% de casos de uso
- [ ] Errores de compilaci√≥n son claros y accionables
- [ ] Visualizaci√≥n ayuda a debugging
- [ ] Documentaci√≥n completa de sintaxis YAML

**Tiempo Estimado:** 2 meses

**Deliverables:**
- Compiler robusto con tests
- JSON Schema para YAML
- VSCode extension con autocomplete (nice-to-have)
- Tutorial completo de YAML DSL

---

### Fase 4: Zero-Leakage ‚Üí v0.4.0 (3 meses)

**Objetivo:** Arquitectura hexagonal completa (ADR v1.3 completo)

**Versi√≥n Objetivo:** `0.4.0` (Release Candidate)

**Features:**
- ‚úÖ **Action Registry** - Decoradores para actions
- ‚úÖ **Validator Registry** - Validadores sem√°nticos
- ‚úÖ **Output Mapping** - Desacoplamiento de datos
- ‚úÖ **Plugin System** - Extensibilidad
- ‚úÖ **GEPA Optimizer** - State-of-the-art optimization

**Implementaci√≥n:**
```python
# soni/registry.py
class ActionRegistry:
    _actions: Dict[str, Callable] = {}
    
    @classmethod
    def register(cls, name: str):
        def decorator(func: Callable):
            cls._actions[name] = func
            return func
        return decorator
    
    @classmethod
    def get(cls, name: str) -> Callable:
        if name not in cls._actions:
            raise ActionNotFoundError(f"Action '{name}' not registered")
        return cls._actions[name]

# Usage
from soni.registry import action

@action("search_flights")
async def search_flights(
    origin: str,
    destination: str,
    date: datetime
) -> FlightSearchResult:
    # Implementation
    pass
```

**YAML Final:**
```yaml
# Purely semantic - no technical details
actions:
  search_flights:
    description: "Search for available flights"
    params: [origin, destination, date]
    map_outputs:
      num_flights: flight_count
      options: flight_list
      cheapest_price: min_price

entities:
  - name: airport_code
    validators:
      - is_valid_iata  # Semantic, not regex
      - is_major_airport
```

**Criterios de √âxito:**
- [ ] 100% separaci√≥n entre YAML y c√≥digo
- [ ] Cambios en API externa no requieren cambio de YAML
- [ ] Analista de negocio puede editar YAML sin dev
- [ ] Sistema de plugins funcional

**Tiempo Estimado:** 2-3 meses

**Deliverables:**
- Sistema de registry completo
- Plugin examples
- Migraci√≥n guide de v0.3.0 a v0.4.0
- Case study: integrando nueva API sin tocar YAML

---

### Fase 5: Release 1.0.0 - ADR Completo (1-2 meses)

**Objetivo:** Validaci√≥n completa del ADR-001 y release estable

**Versi√≥n Objetivo:** `1.0.0` (Stable Release)

**Criterios para 1.0.0:**
- ‚úÖ Todas las fases anteriores completadas (0.1.0 ‚Üí 0.4.0)
- ‚úÖ ADR-001 completamente implementado (todas las features v1.3)
- ‚úÖ Tests de integraci√≥n E2E pasando
- ‚úÖ Documentaci√≥n completa y revisada
- ‚úÖ Al menos 1 caso de uso en producci√≥n
- ‚úÖ Performance benchmarks cumplidos
- ‚úÖ Sin bugs cr√≠ticos conocidos

**Actividades:**
- Auditor√≠a completa de c√≥digo
- Security review
- Performance testing exhaustivo
- Documentaci√≥n final
- Preparaci√≥n de release notes
- Community outreach

**Tiempo Estimado:** 1-2 meses

**Deliverables:**
- Release 1.0.0 estable
- Release notes completos
- Migration guide desde 0.x
- Production deployment guide
- Community announcement

---

### Fase 6: Polish y Ecosystem (Post-1.0, Ongoing)

**Features:**
- üìö Documentaci√≥n profesional (docs site)
- üé® Ejemplos variados (travel, banking, support)
- üîå Integraciones (Slack, Discord, WhatsApp)
- üìä Monitoring y observability (LangSmith)
- üß™ Testing framework robusto
- üéì Tutorials y screencasts

---

## 6. Validaciones T√©cnicas Pre-Inicio

Antes de empezar desarrollo, ejecuta estos experimentos:

### 6.1 Validaci√≥n DSPy Optimization

**Objetivo:** Verificar que optimizaci√≥n funciona para tu caso de uso

```python
# experiments/01_dspy_validation.py
import dspy
from dspy.teleprompt import MIPROv2

# 1. Define tu signature
class IntentExtraction(dspy.Signature):
    """Extract user intent and entities from message"""
    message = dspy.InputField()
    intent = dspy.OutputField(desc="User's intent (book_flight, cancel, ...)")
    entities = dspy.OutputField(desc="Extracted entities as JSON")

# 2. Create module
class SimpleNLU(dspy.Module):
    def __init__(self):
        self.predict = dspy.Predict(IntentExtraction)
    
    def forward(self, message):
        return self.predict(message=message)

# 3. Setup LM
lm = dspy.LM('openai/gpt-4o-mini')
dspy.configure(lm=lm)

# 4. Create trainset (m√≠nimo 20 ejemplos)
trainset = [
    dspy.Example(
        message="I want to fly to Paris tomorrow",
        intent="book_flight",
        entities='{"destination": "Paris", "date": "tomorrow"}'
    ).with_inputs("message"),
    # ... m√°s ejemplos
]

# 5. Define metric
def intent_accuracy(example, pred, trace=None):
    return example.intent == pred.intent

# 6. Optimize
teleprompter = MIPROv2(metric=intent_accuracy, auto="light")
optimized_nlu = teleprompter.compile(
    SimpleNLU(),
    trainset=trainset
)

# 7. Test
test_message = "Book me a flight to London"
result = optimized_nlu(message=test_message)
print(f"Intent: {result.intent}")
print(f"Entities: {result.entities}")

# 8. Compare before/after
baseline_nlu = SimpleNLU()
print("\n=== Baseline ===")
print(baseline_nlu(message=test_message))

print("\n=== Optimized ===")
print(optimized_nlu(message=test_message))
```

**Criterio de √âxito:**
- [ ] Optimizaci√≥n completa sin errores
- [ ] Mejora medible en accuracy (al menos +5%)
- [ ] Tiempo de optimizaci√≥n < 10 minutos

---

### 6.2 Validaci√≥n LangGraph Streaming

**Objetivo:** Verificar streaming async con FastAPI

```python
# experiments/02_langgraph_streaming.py
from langgraph.graph import StateGraph, START, END
from typing_extensions import TypedDict
from fastapi import FastAPI
from fastapi.responses import StreamingResponse
import asyncio

# 1. Define state
class State(TypedDict):
    messages: list[str]
    response: str

# 2. Define async node
async def generate_response(state: State):
    # Simulate streaming LLM
    full_response = "This is a streaming response from LangGraph"
    chunks = full_response.split()
    
    response = ""
    for chunk in chunks:
        await asyncio.sleep(0.1)  # Simulate latency
        response += chunk + " "
    
    return {"response": response.strip()}

# 3. Build graph
graph = StateGraph(State)
graph.add_node("generate", generate_response)
graph.add_edge(START, "generate")
graph.add_edge("generate", END)
compiled_graph = graph.compile()

# 4. FastAPI integration
app = FastAPI()

@app.post("/chat/stream")
async def chat_stream(message: str):
    async def generate():
        async for chunk in compiled_graph.astream(
            {"messages": [message]},
            stream_mode="values"
        ):
            if "response" in chunk:
                yield f"data: {chunk['response']}\n\n"
    
    return StreamingResponse(
        generate(),
        media_type="text/event-stream"
    )

# 5. Test
if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)
```

**Criterio de √âxito:**
- [ ] Streaming funciona sin errores
- [ ] Chunks llegan en orden correcto
- [ ] Compatible con SSE (Server-Sent Events)

---

### 6.3 Validaci√≥n Persistencia Async

**Objetivo:** Verificar checkpointing con aiosqlite

```python
# experiments/03_async_persistence.py
import aiosqlite
from langgraph.checkpoint.aiosqlite import AsyncSqliteSaver
from langgraph.graph import StateGraph, START, END

# 1. Setup checkpointer
async def test_persistence():
    async with AsyncSqliteSaver.from_conn_string("./test.db") as checkpointer:
        # 2. Create graph with checkpointing
        graph = StateGraph(State)
        graph.add_node("step1", lambda s: {"count": s.get("count", 0) + 1})
        graph.add_edge(START, "step1")
        graph.add_edge("step1", END)
        
        app = graph.compile(checkpointer=checkpointer)
        
        # 3. Run with thread_id for persistence
        config = {"configurable": {"thread_id": "test-conversation"}}
        
        result1 = await app.ainvoke({"count": 0}, config)
        print(f"First run: {result1}")
        
        # 4. Resume same conversation
        result2 = await app.ainvoke({}, config)
        print(f"Second run (resumed): {result2}")

asyncio.run(test_persistence())
```

**Criterio de √âxito:**
- [ ] Estado persiste entre invocaciones
- [ ] M√∫ltiples conversaciones simult√°neas funcionan
- [ ] No hay race conditions

---

## 7. M√©tricas de √âxito

### 7.1 M√©tricas T√©cnicas

**v0.1.0 - MVP (Fase 1):**
- [ ] Intent accuracy > 85% (post-optimization)
- [ ] Entity extraction F1 > 80%
- [ ] Latencia p95 < 3s
- [ ] 0 crashes en 100 conversaciones de prueba

**v0.2.0 - Performance (Fase 2):**
- [ ] Latencia p95 < 1.5s
- [ ] Throughput > 10 conversaciones/segundo
- [ ] Streaming latency to first token < 500ms
- [ ] Memory usage < 500MB por conversaci√≥n

**v0.3.0 - DSL Compiler (Fase 3):**
- [ ] YAML compilation success rate > 95%
- [ ] Compiler errors son accionables (no stack traces crudos)
- [ ] Compiled graphs visualizables autom√°ticamente

**v0.4.0 - Zero-Leakage (Fase 4):**
- [ ] 0 detalles t√©cnicos en YAML
- [ ] Cambio de API externa no requiere cambio de YAML
- [ ] Plugin system funciona para 3+ casos de uso

**v1.0.0 - Release Estable (Fase 5):**
- [ ] Todas las m√©tricas anteriores cumplidas
- [ ] Test coverage > 80%
- [ ] 0 bugs cr√≠ticos conocidos
- [ ] Documentaci√≥n 100% completa
- [ ] Al menos 1 deployment en producci√≥n validado

### 7.2 M√©tricas de Producto

**Adopci√≥n:**
- GitHub stars > 100 (6 meses post-launch)
- Contributors externos > 5 (1 a√±o)
- Production deployments > 10 (1 a√±o)

**Documentaci√≥n:**
- Quickstart funcional en < 10 minutos
- 5+ ejemplos end-to-end
- API docs completa

**Comunidad:**
- Discord/Slack community activo
- Response time a issues < 48h
- Monthly blog posts / tutorials

---

## 8. Decisi√≥n Final y Recomendaciones

### 8.1 Veredicto de Viabilidad

**Rating Global: 8.5/10** ‚úÖ

| Dimensi√≥n | Score | Justificaci√≥n |
|-----------|-------|---------------|
| **Fundamentos T√©cnicos** | 9/10 | DSPy + LangGraph son rock-solid |
| **Innovaci√≥n** | 9/10 | Zero-Leakage + Auto-opt es √∫nico |
| **Viabilidad Comercial** | 7/10 | Nicho claro pero competido |
| **Complejidad** | 6/10 | Ambiciosa, riesgo de over-eng |
| **Time-to-Market** | 7/10 | MVP en 3 meses es factible |

### 8.2 Recomendaciones Cr√≠ticas

#### ‚úÖ MANTENER

1. **DSPy como pilar central** - Es tu diferenciador #1
2. **Zero-Leakage architecture** - Innovaci√≥n arquitect√≥nica clave
3. **Async-first** - Requisito para producci√≥n moderna
4. **100% Open Source** - Tu ventaja vs Rasa Pro

#### ‚ö†Ô∏è AJUSTAR

1. **Narrativa competitiva**
   - ‚ùå "Rasa est√° obsoleto"
   - ‚úÖ "Soni elimina prompt engineering manual con optimizaci√≥n autom√°tica"

2. **Roadmap**
   - ‚ùå Implementar ADR completo (v1.3) de golpe
   - ‚úÖ Fases incrementales (0.1.0 ‚Üí 0.4.0 ‚Üí 1.0.0) con validaci√≥n

3. **Scope inicial**
   - ‚ùå Todos los features del ADR
   - ‚úÖ MVP funcional ‚Üí iterar basado en feedback

#### ‚ùå EVITAR

1. **Over-engineering prematuro** - Resiste la tentaci√≥n de perfecci√≥n
2. **Feature creep** - Mant√©n scope limitado hasta tener usuarios
3. **Competir directamente con Rasa Pro** - Son mercados diferentes

### 8.3 Plan de Acci√≥n Inmediato

**Semana 1-2: Validaci√≥n T√©cnica**
```
‚òê Ejecutar experimentos de validaci√≥n (secci√≥n 6)
‚òê Confirmar que DSPy optimization funciona para tu dominio
‚òê Confirmar que LangGraph streaming cumple requisitos
‚òê Documentar resultados
```

**Semana 3-4: Setup de Proyecto**
```
‚òê Crear repo GitHub (soni-framework)
‚òê Setup b√°sico (poetry, pre-commit, testing)
‚òê Definir arquitectura de paquetes
‚òê Escribir ADR-002: Technology Stack Validation
```

**Mes 2-4: MVP Development (v0.1.0)**
```
‚òê Implementar SoniDU (dspy.Module)
‚òê Implementar LangGraph runtime b√°sico
‚òê YAML parser simple
‚òê Ejemplo end-to-end funcional
‚òê Tests b√°sicos
```

**Mes 5: Alpha Release (v0.1.0)**
```
‚òê Documentaci√≥n b√°sica
‚òê Publicar v0.1.0 en GitHub
‚òê Post en Reddit/HN
‚òê Recoger feedback
‚òê Planificar siguiente fase (v0.2.0)
```

### 8.4 Se√±ales de Alerta (Stop Conditions)

Si durante desarrollo encuentras:

üõë **STOP si:**
- DSPy optimization no mejora accuracy en tu dominio
- Latencia post-optimization es > 5s consistentemente
- Compiler YAML‚ÜíGraph es imposiblemente complejo
- No puedes implementar MVP en 4 meses

‚ö†Ô∏è **REEVALUAR si:**
- Rasa Pro anuncia optimizaci√≥n autom√°tica
- Aparece competidor directo con funding
- Comunidad DSPy/LangGraph se fragmenta
- No hay inter√©s tras alpha release

### 8.5 Conclusi√≥n Final

Tu ADR-001 es **t√©cnicamente s√≥lido y viable**. Las tecnolog√≠as que propones (DSPy, LangGraph) est√°n maduras y en producci√≥n. Tu arquitectura Zero-Leakage es innovadora y resuelve problemas reales.

**Los ajustes necesarios son estrat√©gicos, no t√©cnicos:**
1. Reposicionar vs competencia (enfoque en auto-optimization)
2. Implementar incrementalmente (no todo de golpe)
3. Validar temprano con usuarios reales

**El proyecto tiene potencial de √©xito si:**
- Ejecutas con disciplina el roadmap incremental (0.1.0 ‚Üí 0.4.0 ‚Üí 1.0.0)
- Mantienes el foco en diferenciadores clave
- Construyes comunidad activamente
- Iteras basado en feedback real
- No te apresuras a 1.0.0 sin completar todas las fases del ADR

**Mi recomendaci√≥n:** ‚úÖ **PROCEDER CON IMPLEMENTACI√ìN**

El mercado de frameworks ToD open source tiene espacio para una alternativa moderna, developer-friendly, con optimizaci√≥n autom√°tica. Tu combinaci√≥n de DSPy + LangGraph + Zero-Leakage es √∫nica.

**Roadmap Resumido:**
- **v0.1.0** (3 meses): MVP funcional
- **v0.2.0** (2 meses): Performance y UX
- **v0.3.0** (2 meses): DSL Compiler
- **v0.4.0** (3 meses): Zero-Leakage (ADR completo)
- **v1.0.0** (1-2 meses): Validaci√≥n y release estable
- **Total estimado:** 11-13 meses hasta 1.0.0

---

## 9. Referencias y Fuentes

### Documentaci√≥n Oficial Verificada

**DSPy:**
- https://dspy.ai/api/optimizers/MIPROv2/
- https://dspy.ai/api/optimizers/SIMBA/
- https://dspy.ai/api/optimizers/GEPA/overview/
- https://github.com/stanfordnlp/dspy

**LangGraph:**
- https://docs.langchain.com/oss/python/langgraph/streaming
- https://www.langchain.com/langgraph
- https://github.com/langchain-ai/langgraph

**Papers:**
- Khattab et al. (2024): "DSPy: Compiling Declarative Language Model Calls"
- Agrawal et al. (2025): "GEPA: Reflective Prompt Evolution Can Outperform RL"

### An√°lisis Competitivo

**Rasa:**
- https://rasa.com/docs/reference/config/components/llm-configuration
- https://rasa.com/docs/reference/changelogs/rasa-pro-changelog
- https://www.communeify.com/en/blog/what-is-rasa/

### Art√≠culos y Blogs

- "Grokking MIPROv2 - the new optimizer from DSPy" (Langtrace)
- "Learning DSPy (3): Working with optimizers" (The Data Quarry, Oct 2025)
- "Building Real-Time AI Apps with LangGraph, FastAPI & Streamlit" (Medium)

---

## Ap√©ndice A: Tabla de Decisiones Arquitecturales

| Decisi√≥n | Opci√≥n Elegida | Alternativas Consideradas | Justificaci√≥n |
|----------|----------------|---------------------------|---------------|
| Framework de Optimizaci√≥n | DSPy | Prompt engineering manual, LangChain prompts | Auto-optimization, soporte para m√∫ltiples optimizadores |
| Runtime de Di√°logo | LangGraph | Rasa, Custom state machine | Async nativo, streaming, checkpointing |
| Optimizador Principal | MIPROv2 | SIMBA, GEPA, BootstrapFewShot | Balance entre rendimiento y velocidad |
| Persistencia | SQLite/PostgreSQL async | Redis, Filesystem | Simplicidad (SQLite), escalabilidad (PostgreSQL) |
| API Framework | FastAPI | Flask, Django | Async nativo, validaci√≥n autom√°tica, docs |
| DSL | YAML procedural | Python DSL, JSON, Custom | Legibilidad para no-programadores |

---

## Ap√©ndice B: Glosario de T√©rminos

**ToD (Task-oriented Dialogue):** Sistema de di√°logo enfocado en completar tareas espec√≠ficas (booking, support, etc.)

**DSPy:** Framework para programar (no promptear) LLMs con optimizaci√≥n autom√°tica

**MIPROv2:** Optimizador que usa Bayesian Optimization para encontrar mejores prompts

**SIMBA:** Optimizador introspectivo que analiza fallos del modelo

**GEPA:** Optimizador evolutivo con reflexi√≥n textual

**LangGraph:** Framework para construir aplicaciones stateful multi-actor con LLMs

**StateGraph:** Grafo de estados en LangGraph para control de flujo

**Zero-Leakage:** Arquitectura donde detalles t√©cnicos no "filtran" al YAML sem√°ntico

**Dynamic Scoping:** Inyectar solo informaci√≥n relevante en contexto del LLM

**CALM:** Conversational AI with Language Models (arquitectura de Rasa Pro)

---

**Fin del Documento**

---

*Este an√°lisis ha sido realizado con investigaci√≥n actualizada al 29 de Noviembre de 2025. Se recomienda re-validar hallazgos cr√≠ticos antes de decisiones mayores de arquitectura.*